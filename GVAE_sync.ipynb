{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn.models import InnerProductDecoder, VGAE\n",
    "from torch_geometric.nn.conv import GCNConv\n",
    "from torch_geometric.utils import negative_sampling, remove_self_loops, add_self_loops\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "from typing import Optional\n",
    "from torch_scatter import scatter_add\n",
    "from torch_sparse import coalesce\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops, to_scipy_sparse_matrix\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from numpy import linalg as LA\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse.linalg import eigs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Mgnetic_conv import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VAGE MAX_LOGSTD = 10\n",
    "MAX_LOGSTD = 10\n",
    "\n",
    "class MagConvEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, k , q ,trainable_q):\n",
    "        super(MagConvEncoder, self).__init__()\n",
    "        self.magconv_shared = MagNetConv(in_channels, hidden_channels,k,q,trainable_q)\n",
    "        self.magconv_mu = MagNetConv(hidden_channels, out_channels,k,q,trainable_q)\n",
    "        self.magconv_logvar = MagNetConv(hidden_channels, out_channels,k,q,trainable_q)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        ## x_real & x_img as input\n",
    "        x_real = x.real.float()\n",
    "        x_imag_1 = x * 1j\n",
    "        x_imag = x_imag_1.float()\n",
    "        # print(x_real,x_imag_1,x_imag)\n",
    "        # all_zeros = torch.all(x_real == 0)\n",
    "        # print(\"Are all elements zeros?\", all_zeros)\n",
    "        # x_imag = x.clone\n",
    "        ### should be complex relu\n",
    "\n",
    "###ReLU\n",
    "## 3RELU -- mu and log !use x -- medium --  80+\n",
    "## 3RELU -- mu and log use x -- stuck\n",
    "## 1Act == 0Act-- since mu and log do not include x -- 94.8 optimal\n",
    "## 1RELU（first layter） -- mu and log indeed include x -- 93\n",
    "## 0 act -- mu and log include x -- 91 \n",
    "        x = self.magconv_shared(x_real,x_imag,edge_index)[0]\n",
    "        mu = self.magconv_mu(x_real,x_imag,edge_index)[0]\n",
    "        logvar = self.magconv_logvar(x_real,x_imag,edge_index)[0]\n",
    "        return mu,logvar\n",
    "        # x_2 = F.relu(self.magconv_shared(x_real,x_imag,edge_index)[0])\n",
    "        # x_real_2 = x_2.real.float()\n",
    "        # x_imag_2 = x_2.real * 1j \n",
    "        # x_imag_2 = x_imag_2.float()\n",
    "        # mu = F.relu(self.magconv_mu(x_real_2,x_imag_2,edge_index)[0])\n",
    "        # logvar = F.relu(self.magconv_logvar(x_real_2,x_imag_2,edge_index)[0])\n",
    "        # return mu,logvar\n",
    "\n",
    "\n",
    "class SyncRankDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SyncRankDecoder, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self,z,g = 0.5):\n",
    "        ##  regard latent representation as the input comparison matrix to the syncrank decoder\n",
    "        C = z\n",
    "        n = C.shape[0]\n",
    "        Theta = 2 * np.pi * g * C / (n-1)\n",
    "        # H = np.exp(1j * Theta)\n",
    "        # H = torch.exp(1j * Theta)\n",
    "        # d = torch.sum(torch.abs(H), dim=1).detach() + 1e-10\n",
    "        # v, psi = eigs(1j * torch.diag(d**(-1)) @ H, 1, which='LR')\n",
    "        H = torch.exp(1j * Theta)\n",
    "        d = torch.sum(torch.abs(H), dim=1).detach() + 1e-10\n",
    "\n",
    "        # Convert d to a diagonal matrix\n",
    "        D_inv = torch.diag(1.0 / d)\n",
    "        # Compute eigenvalues and eigenvectors using torch.linalg.eig\n",
    "        H = torch.tensor(H, dtype=torch.complex64)  # Convert H to a complex tensor\n",
    "        A = 1j * D_inv @ H\n",
    "        eigenvalues, eigenvectors = torch.linalg.eig(A)\n",
    "        # Get the largest real part eigenvalue and its corresponding eigenvector\n",
    "        largest_eigenvalue_idx = torch.argmax(eigenvalues.real)\n",
    "        psi = eigenvectors[:, largest_eigenvalue_idx].real\n",
    "\n",
    "\n",
    "        # d = np.sum(np.abs(H),axis = 1) + 1e-10\n",
    "        # v,psi = eigs(1j * np.diag(d**(-1)) @ H,1,which = 'LR')\n",
    "        # r_hat =  psi / np.abs(psi)\n",
    "        # r_hat = r_hat.reshape(n)\n",
    "        psi = psi.reshape(n)\n",
    "        angles_radians = np.angle(psi)\n",
    "        angles_modulo_2pi = np.mod(angles_radians, 2 * np.pi)\n",
    "        angles_degrees = np.degrees(angles_modulo_2pi)\n",
    "        print('angle_degrees is ',angles_degrees)\n",
    "        sorted_indices = np.argsort(angles_degrees)\n",
    "        print('label of degree from smallest to largest',sorted_indices)\n",
    "        return sorted_indices ## decoder here return the label --  project the latent space to a new angle space \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class DeepVGAE(VGAE):\n",
    "    def __init__(self,in_channels:int,hidden_channels:int, out_channels:int, K:int, q:float, trainable_q:bool):\n",
    "        super(DeepVGAE, self).__init__(encoder= MagConvEncoder(in_channels,\n",
    "                                                        hidden_channels,\n",
    "                                                        out_channels,\n",
    "                                                        K,\n",
    "                                                        q,\n",
    "                                                        trainable_q\n",
    "                                                        ),\n",
    "                                        decoder = SyncRankDecoder())\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    ## embedding z\n",
    "    def encode(self,x,edge_index):\n",
    "        # print(self.encoder)\n",
    "        self.__mu__, self.__logstd__ = self.encoder(x,edge_index)\n",
    "        # gaussian_noise = torch.randn(x.size(0), self.out_channels)\n",
    "        # print(self.training)\n",
    "        # z = self.__mu__ + gaussian_noise * torch.exp(self.__logstd__ )\n",
    "        z = self.reparametrize(self.__mu__, self.__logstd__)\n",
    "        return z\n",
    "\n",
    "    def forward(self,x,edge_index):\n",
    "        x_real = x.real.float()\n",
    "        z = self.encode(x_real, edge_index)\n",
    "        ## forward_all \n",
    "        output = self.decoder.forward(z)\n",
    "        return output\n",
    "\n",
    "    def loss(self, x, pos_edge_index):\n",
    "        z = self.encode(x, pos_edge_index)\n",
    "        # Original Loss function\n",
    "        # pos_loss = -torch.log(\n",
    "        #     self.decoder(z, pos_edge_index) + 1e-15).mean()\n",
    "        # neg_edge_index = negative_sampling(all_edge_index, z.size(0), pos_edge_index.size(1))\n",
    "        # neg_loss = -torch.log(1 - self.decoder(z, neg_edge_index) + 1e-15).mean()\n",
    "        # kl_loss = 1 / x.size(0) * self.kl_loss() \n",
    "\n",
    "        ##new losss funciton\n",
    "        display(z)\n",
    "        print(z.shape)\n",
    "        n = z.shape[0]\n",
    "        s_projection = self.decoder(z)\n",
    "        obj = 9999999999999\n",
    "        best_shift = 0\n",
    "        for shift in range(n):\n",
    "            obj1 = self.upset(s_projection,z,shift)\n",
    "            print(obj1)\n",
    "            if obj1 < obj:\n",
    "                obj = obj1\n",
    "                best_shift = shift\n",
    "                # print(circular_shift(s,best_shift))\n",
    "        repre = self.circular_shift(s_projection,best_shift)\n",
    "        obj_loss = obj\n",
    "        return obj_loss\n",
    "        \n",
    "    def circular_shift(self, x, shift):\n",
    "            return np.concatenate((x[-shift:], x[:-shift]))\n",
    "    \n",
    "    def outer_product(self, x, y):\n",
    "        return np.outer(x, y)\n",
    "    \n",
    "    def hadamard_product(self, x, y):\n",
    "        return x * y\n",
    "    \n",
    "    def upset(self, s, C, shift):\n",
    "        sigma_s = self.circular_shift(s, shift)\n",
    "        n = len(s)\n",
    "        sigma_s = sigma_s.reshape(n, 1)\n",
    "        sigma_outer_ones_T = self.outer_product(sigma_s, np.ones(len(sigma_s)))\n",
    "        ones_outer_sigma_T = self.outer_product(np.ones(len(sigma_s)), sigma_s.T)\n",
    "        term1 = sigma_outer_ones_T - ones_outer_sigma_T\n",
    "        result = self.hadamard_product(term1, [C!=0])\n",
    "        return 0.5 * (np.sum( np.abs(np.sign(result) - np.sign(C))))\n",
    "\n",
    "\n",
    "    def single_test(self, x, train_pos_edge_index, test_pos_edge_index, test_neg_edge_index):\n",
    "        with torch.no_grad():\n",
    "            z = self.encode(x, train_pos_edge_index)\n",
    "        roc_auc_score, average_precision_score = self.test(z, test_pos_edge_index, test_neg_edge_index)\n",
    "        return roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "torch.manual_seed(3407)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leoenoch/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], val_pos_edge_index=[2, 263], test_pos_edge_index=[2, 527], train_pos_edge_index=[2, 8976], train_neg_adj_mask=[2708, 2708], val_neg_edge_index=[2, 263], test_neg_edge_index=[2, 527])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "dataset = Planetoid(\"datasets\",'Cora', transform=T.NormalizeFeatures())\n",
    "data = dataset[0].to(device)\n",
    "all_edge_index = data.edge_index\n",
    "data = train_test_split_edges(data, 0.05, 0.1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepVGAE(1433,1433,2708,2,0.25,True)\n",
    "optimizer = Adam(model.parameters(), lr= 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.__repr__ of DeepVGAE(\n",
       "  (encoder): MagConvEncoder(\n",
       "    (magconv_shared): MagNetConv(1433, 1433, K=2, normalization=sym)\n",
       "    (magconv_mu): MagNetConv(1433, 2708, K=2, normalization=sym)\n",
       "    (magconv_logvar): MagNetConv(1433, 2708, K=2, normalization=sym)\n",
       "  )\n",
       "  (decoder): SyncRankDecoder()\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.__repr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss = model.loss(data.x, data.train_pos_edge_index) ##self.train = True\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 2 == 0:\n",
    "      model.eval()\n",
    "      roc_auc, ap = model.single_test(data.x,\n",
    "                                        data.train_pos_edge_index,\n",
    "                                        data.test_pos_edge_index,\n",
    "                                        data.test_neg_edge_index) ## self.train = False\n",
    "      print(\"Epoch {} - Loss: {} ROC_AUC: {} Precision: {}\".format(epoch, loss.cpu().item(), roc_auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
